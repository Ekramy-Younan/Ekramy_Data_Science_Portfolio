# Ekramy_Data_Science_Portfolio
Data Science Projects

# [Hadoop Installation]
![image](https://user-images.githubusercontent.com/76533174/155047078-85f1d2bd-c2eb-4efd-92ca-c11e30f55bde.png)
![image](https://user-images.githubusercontent.com/76533174/155047102-5a4b0f9f-1179-4454-a2a5-ae344ed12217.png)
![image](https://user-images.githubusercontent.com/76533174/155047115-54a2b423-f71f-4fe7-9e2b-aa58bd74a098.png)
![image](https://user-images.githubusercontent.com/76533174/155047134-1f85b643-0036-4d93-8306-b5ce606293e3.png)

# [Hadoop - MapReduce - Modify mapper program to make a reasonable word count program]
![image](https://user-images.githubusercontent.com/76533174/155048858-992a5381-ca00-4afe-a3a9-da84c97a50b0.png)
![image](https://user-images.githubusercontent.com/76533174/155048941-0ecddbdb-e0db-4ee0-be7c-83f4d440b8f7.png)
![image](https://user-images.githubusercontent.com/76533174/155048976-26bbcfe1-89f9-4ba2-9bd3-23bf28b023e0.png)
![image](https://user-images.githubusercontent.com/76533174/155048996-870cb8e3-6726-4cfd-9c09-9f072a20bab3.png)
![image](https://user-images.githubusercontent.com/76533174/155049025-d7a2d63e-2c17-483c-b154-7cc1cc06fee4.png)

# [Hadoop - Use hadoop to run mapreduce]
![image](https://user-images.githubusercontent.com/76533174/155049099-7ebbb01a-d20c-485d-a69c-1853f0d2d168.png)
![image](https://user-images.githubusercontent.com/76533174/155049126-e281ceea-ac3f-4d27-b26d-9fe084260701.png)
![image](https://user-images.githubusercontent.com/76533174/155049229-dbb9cba6-e167-4637-9037-476fbbe37dc5.png)

# [Hadoop - Word Histogram of your favorite book]
![image](https://user-images.githubusercontent.com/76533174/155049354-7645fc71-dd6d-4d0a-b42f-bab389de3d14.png)
![image](https://user-images.githubusercontent.com/76533174/155049369-28fbb006-40e9-4736-8587-3004ab3b3f5d.png)
![image](https://user-images.githubusercontent.com/76533174/155049463-1aaac3ba-0e8b-4835-9586-80c876605bc1.png)
![image](https://user-images.githubusercontent.com/76533174/155049548-1e016726-70f8-4c27-bafd-3497eec86636.png)
![image](https://user-images.githubusercontent.com/76533174/155049595-e0047241-3f43-4a98-af97-da97f574b3ab.png)

# [Apache Spark - Verify that you can write work count in spark]
![image](https://user-images.githubusercontent.com/76533174/155050892-37213db2-4f85-47f0-bc6c-bbebf71d8c11.png)
![image](https://user-images.githubusercontent.com/76533174/155050932-5afec84f-0061-401c-a323-4a44a9ccb621.png)
![image](https://user-images.githubusercontent.com/76533174/155051143-be9f5d6c-f3bc-4b8f-82e0-daed4836311f.png)
![image](https://user-images.githubusercontent.com/76533174/155051168-3ba091f5-b03a-485b-8fab-d7602cb6ea11.png)
![image](https://user-images.githubusercontent.com/76533174/155051187-50703dd8-aace-402b-a58d-d2a78cc5ef91.png)
![image](https://user-images.githubusercontent.com/76533174/155051221-7c53d0eb-aa78-4e5b-a60c-f7bff27a8f43.png)
![image](https://user-images.githubusercontent.com/76533174/155051245-a37493f4-ad13-44b2-b0f5-91fbf00f3bb8.png)

# [Apache Spark - Create a function that  takes a word string as argument and returns the same word in lowercase and without any punctuation, or trailing spaces]
![image](https://user-images.githubusercontent.com/76533174/155052271-44bace66-5f45-4943-81f0-198c37138ab1.png)
![image](https://user-images.githubusercontent.com/76533174/155052301-2c8aaad9-5248-468a-8cbf-f99b6712cb03.png)

# [Project: Natural Learning Processing - using DecisionTreeClassifier]
 * I used Congenital_disorders and Infectious_diseases from the Wikipedia folder.
 * The following metrics table for the max features in [1,5,10,50,100,500] and max_depth in [3 & 2].
 * ![image](https://user-images.githubusercontent.com/76533174/154201106-e25da8c8-f807-405c-830c-791a5680a0e6.png)
 * ![image](https://user-images.githubusercontent.com/76533174/154201125-ba9ee8a5-9715-408f-9ae7-13c2d831b7d1.png)

# [Project: Natural Learning Processing - using Beautiful Soup]
 * Gentle Start to Natural Language Processing using Python
 * Reference: https://towardsdatascience.com/gentle-start-to-natural-language-processing-using-python-6e46c07addf3
 * What is NLP ?
   - Natural language processing (NLP) is about developing applications and services that are able to understand human languages.
   - Some Practical examples of NLP are speech recognition for eg: google voice search, understanding what the content is about or sentiment analysis etc.
 * How do I Start with NLP using Python?
   - The natural language toolkit (NLTK) is the most popular library for natural language processing (NLP) which was written in Python and has a big community behind it.
   - NLTK also is very easy to learn, actually, it’s the easiest natural language processing (NLP) library that you’ll use.
   - In this NLP Tutorial, we will use Python NLTK library.

* First, we will grab a webpage and analyze the text to see what the page is about.
* urllib module will help us to crawl the webpage
* It’s pretty clear from the link that the page is about SpaceX now let us see whether our code is able to correctly identify the page’s context.
* We will use Beautiful Soup which is a Python library for pulling data out of HTML and XML files. We will use beautiful soup to clean our webpage text of HTML tags.

* Count word Frequency
* nltk offers a function FreqDist() which will do the job for us. Also, we will remove stop words (a, at, the, for etc) from our web page as we don't need them to hamper our word frequency count.
* We will plot the graph for most frequently occurring words in the webpage in order to get the clear picture of the context of the web page
* ![image](https://user-images.githubusercontent.com/76533174/154213786-26450d4b-fe61-401b-bf2e-63360ad59cd7.png)


# [Project: Predicting Loan Defaults using Deep Learning with Keras & Tensorflow](https://github.com/Ekramy-Younan/Lending-Club-Loan)
Problem Statement:
For companies like Lending Club, predicting loan default with high accuracy is very important. Using the historical Lending Club data from 2007 to 2015, build a deep learning model to predict the chance of default for future loans.

Analysis to be done:
Perform data preprocessing, exploratory data analysis, and feature engineering. Build a deep learning model to predict load default using the historical public data (https://www.lendingcub.com).

Dataset:
The data set used here can be downloaded from here. The CSV file contains complete loan data for all loans issued through 2007–2015, including the current loan status and payment information. Additional features include annual income, public records, revolving balance, and others.

![](/Images/Lending_Club_Loan_Correlation.png)

We only focus on the grids of yellow or very light green. After comparing with the feature description again, I decided to drop:’revol.bal’, ‘days.with.cr.line’, ‘installment’, ‘revol.bal’ revol.bal, day.with.cr.line, installment can represent by annual income. revol.util can represent by int.rate.


# [Project: Income-Qualification](https://github.com/Ekramy-Younan/Income-Qualification)

**DESCRIPTION
  * Identify the level of income qualification needed for the families in Latin America.

**Problem Statement Scenario:
  * Many social programs have a hard time ensuring that the right people are given enough aid. It’s tricky when a program focuses on the poorest segment of the population. This segment of the population can’t provide the necessary income and expense records to prove that they qualify.
  * In Latin America, a popular method called Proxy Means Test (PMT) uses an algorithm to verify income qualification. With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling or the assets found in their homes to classify them and predict their level of need.
  * While this is an improvement, accuracy remains a problem as the region’s population grows and poverty declines.
  * The Inter-American Development Bank (IDB)believes that new methods beyond traditional econometrics, based on a dataset of Costa Rican household characteristics, might help improve PMT’s performance.

![](/Images/Income_Qualification_Correlation.png)

Create correlation matrix
Select upper triangle of correlation matrix
Find index of feature columns with correlation greater than 0.95


# [Project: Mercedes-Benz-Greener-Manufacturing](https://github.com/Ekramy-Younan/Mercedes-Benz-Greener-Manufacturing)
**Description:

Reduce the time a Mercedes-Benz spends on the test bench.

**Problem Statement Scenario:

"Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include the passenger safety cell with a crumple zone, the airbag, and intelligent assistance systems. 
Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium carmakers. Mercedes-Benz is the leader in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams. 
To ensure the safety and reliability of every unique car configuration before they hit the road, the company’s engineers have developed a robust testing system. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on Mercedes-Benz’s production lines. 
However, optimizing the speed of their testing system for many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. You are required to reduce the time that cars spend on the test bench. 
Others will work with a dataset representing different permutations of features in a Mercedes-Benz car to predict the time it takes to pass testing. Optimal algorithms will contribute to faster testing, resulting in lower carbon dioxide emissions without reducing Mercedes-Benz’s standards."

![](/Images/Mercedes_Change_in_target_value.png)

There doesn't seem to be anything overly suspicious here - looks like a random sort.


# [Project: Uber-Fare-Prediction](https://github.com/Ekramy-Younan/Uber-Fare-Prediction)

**Description:

Design an algorithm which will tell the fare to be charged for a passenger.

**Problem Statement Scenario:

A fare calculator helps a customer in identifying the fare valid for the trip. They are often used by passengers who are new to a city or tourists to get an estimate of travel costs. You are provided with a dataset with features like fare amount, pickup and drop location, passenger count, and so on.

![](/Images/Uber_fare_prediction_fare_amount.png)

In distribution plot also it can be seen that there are some values which are negative fare.


# [Project: Amazon-Employee-Access](https://github.com/Ekramy-Younan/Amazon.com---Employee-Access)

**Description:

Design an algorithm to accurately predict the access status to certain resources of employees

**Problem Statement Scenario:

When employees start working at an organization, they first need to obtain the computer access necessary to fulfil their role. This access may allow employees to read/manipulate resources through various applications or web portals.  
It is assumed that employees fulfilling the functions of a given role will access the same or similar resources. Often, employees figure out the access they need as they encounter roadblocks during their daily work (such as, not being able to log into a reporting portal). 
A knowledgeable supervisor then takes time to manually grant the access needed to overcome the obstacles. As employees change roles within a company, this access discovery/recovery cycle wastes a non-trivial amount of time and money. 
There is a considerable amount of data regarding employees’ roles within an organization and the resources to which they have access. Given the data related to current employees and their provisioned access, models can be built that automatically determine access privileges as employees enter and leave roles within a company. 
These auto-access models seek to minimize the human involvement required to grant or revoke employee access.

![](/Images/amazon_access_Action.png)

